<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Hua Zheng" />

  
  
  
    
  
  <meta name="description" content="Some concerns on reinforcement learning algorithms." />

  
  <link rel="alternate" hreflang="en-us" href="https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/hua.zheng/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/hua.zheng/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/hua.zheng/css/wowchemy.1c5d388abe3a8c1cc9cc92b0304ce78f.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/hua.zheng/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/hua.zheng/media/icon_hu658dc7ef748f26cdf7d87fd659137d7d_44050_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/hua.zheng/media/icon_hu658dc7ef748f26cdf7d87fd659137d7d_44050_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@wowchemy" />
    <meta property="twitter:creator" content="@wowchemy" />
  
  <meta property="og:site_name" content="Zheng.H" />
  <meta property="og:url" content="https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/" />
  <meta property="og:title" content="Some Gaps Between Reinforcement Learning Practice and Theory | Zheng.H" />
  <meta property="og:description" content="Some concerns on reinforcement learning algorithms." /><meta property="og:image" content="https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/featured.jpg" />
    <meta property="twitter:image" content="https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/featured.jpg" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-05-08T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-05-08T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/"
  },
  "headline": "Some Gaps Between Reinforcement Learning Practice and Theory",
  
  "image": [
    "https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/featured.jpg"
  ],
  
  "datePublished": "2022-05-08T00:00:00Z",
  "dateModified": "2022-05-08T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Hua Zheng"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Zheng.H",
    "logo": {
      "@type": "ImageObject",
      "url": "https://zhenghuazx.github.io/hua.zheng/media/icon_hu658dc7ef748f26cdf7d87fd659137d7d_44050_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Some concerns on reinforcement learning algorithms."
}
</script>

  

  

  

  





  <title>Some Gaps Between Reinforcement Learning Practice and Theory | Zheng.H</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="cead3918ea288d986cfa505c2fcd759b" >

  
  
  
  
  
  
  
  
  
  <script src="/hua.zheng/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/hua.zheng/">Zheng.H</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/hua.zheng/">Zheng.H</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/#contact"><span>Contact</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/hua.zheng/uploads/resume.pdf"><span>CV</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  





















  
  


<div class="article-container pt-3">
  <h1>Some Gaps Between Reinforcement Learning Practice and Theory</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Hua Zheng</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May 8, 2022
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  
  
    <span class="middot-divider"></span>
    <a href="/hua.zheng/post/somegapsrl/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/hua.zheng/category/blog/">Blog</a></span>
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 346px;">
  <div style="position: relative">
    <img src="/hua.zheng/post/somegapsrl/featured_hu6f28db4e9200a2afa2f3d509beb90b53_1412462_720x2500_fit_q100_h2_lanczos.webp" width="720" height="346" alt="" class="featured-image">
    <span class="article-header-caption">Image credit: <a href="https://unsplash.com/photos/-hI5dX2ObAs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" target="_blank" rel="noopener"><strong>Unsplash</strong></a></span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>I am recently encountering some theoretical problems during a reinforcement learning (RL) research project. I started to realize how much difference between how people use versus how people prove RL algorithms. Although rarely mentioned in the literature, some gaps indeed exist and may be useful to think a little deeper. It motivates me to write some of my thoughts down.</p>
<p>Note: Some of the practical heuristics might already have theoretical justifications that I do not know or bypassed by some reasonable assumptions. Thus, please correct me if I misunderstand or have mistakes.</p>
<h1 id="experience-replay-cause-bias">Experience Replay Cause Bias</h1>
<p>Off-policy learning is a large category of RL algorithms. it, instead of following the target policy, enables a target policy to be learned by using data from behavior policies. Experience replay is central to off-policy algorithms in deep reinforcement learning (RL). As the fundamental data-generating mechanism in off-policy deep reinforcement learning, it has been shown to improve sample efficiency and stability by storing and randomly replaying a fixed number of the most recently collected transitions for training.</p>
<p>One interesting problem of experience replay is that the stored transitions are inevitably dependent with the current/target policy or value function, because the policy/value function parameter is in fact constructed from those transitions. In other words, all transitions are correlated. It <strong>violates</strong> the following conditional unbiasedness assumption in stochastic policy gradient methods.</p>
<ul>
<li>The estimated gradient is unbiased condition on the history (filtration) $\mathcal{F}_k=\{\xi_1,\ldots,\xi_{k};\theta_0,\theta_1,\ldots,\theta_{k}\}$, such that $\mathbb{E}_\xi[g(\theta_k,\xi)|\mathcal{F}_{k}]=\nabla f(\theta_k)$. ($\mathcal{F}_{k}$ denotes the outcomes up to and including time $k$).</li>
</ul>
<p>In the classical stochastic gradient descent (SGD), the data are assumed to be sampled from a unknown population, which is also referred as to the behavior distribution in off-policy batch RL. However, when you have a growing experience replay buffer in which transitions were continuously collected by following past policies, you won’t have a fixed unknown behavior distribution but a changing known one. The main concerns behind this conditional dependence makes theoretical study of experience replay difficult.</p>
<h1 id="compatibility-of-critic-model">Compatibility of Critic Model</h1>
<p>Compatibility is an important concept in actor-critic methods, which are a popular class of on-policy RL algorithms for computing an optimal policy. The actor-critic consists of two eponymous components. An actor adjusts the parameters of the stochastic policy by stochastic gradient ascent. A critic estimates the action-value function to evaluate the action chosen by current policy. Instead of the unknown true action-value function, an action-value function is used, which introduce the concept of compatibility.</p>
<p>In general, substituting a function approximator for the true action-value (or value) function may introduce bias. However, the bias is zero if the function approximator is compatible, i.e.</p>
<ol>
<li>the function approximator is linear in the score function of policy</li>
<li>parameters of the function approximator are chosen to minimize the mean-squared error of approximated and true action-value function.</li>
</ol>
<p>In practice, condition 2 is usually relaxed in favor of policy evaluation algorithms that estimate the value function more efficiently by temporal-difference learning. However, condition 1 is rarely satisfied. This issues applies to almost all, if not all, modern deep policy optimization algorithms.</p>
<p>Good news is that people has released this issue and some literature are working on relaxing the compatibility constraint for neural network [1-3].</p>
<h1 id="discounted-objective">Discounted Objective</h1>
<p>I had recently revisited the policy gradient theorem proof when working on my actor-critic related paper, which leads to this question.</p>
<p>After a quick literature review I found Russo Alessio mentioned the same issue in his blog [4] and Nota and Thomas [5] had raised concerns about the similar issue by constructing a counterexample. In addition, Naik et al [6] criticize discounted objective as well but in a different context.
I personally used a lot of discounted objective, but still felt unclear on some concepts. Part of the reason comes from inaccurate or ambiguous description and the other part I think comes from the fact that RL is an interdisciplinary area including contribution from optimization, operations research, statistics and computer science.
As a result, people used different terminologies and notations, which further exaggerates the ambiguity.</p>
<p>Now let’s briefly discuss the issue in infinite-horizon MDP setting. For detailed discussion, I recommend reading the blog and literature mentioned above.</p>
<p>In the classic policy gradient theorem, the discounted policy gradient, tells us how to modify the policy parameters, $\theta$, in order to increase $\nabla J_\gamma(\theta)$ , and is given by:</p>

$$
\begin{equation}
\begin{split}
\nabla J_\gamma(\theta)
&= \mathbb{E}_{s_t\sim d^\pi_\gamma,a_t\sim \pi(s_t|a_t)}\left[\left. \nabla \log\pi_\theta(a_t|s_t)Q^\pi_\gamma(s_t,a_t)\right|\theta\right]
\end{split}
\end{equation}
$$

<p>where $d^\pi_\gamma(s)=\int p(s_0)\sum^\infty_{t=0}\gamma^t p^\pi(s_t=s|s_0)d s_0$ is the discounted stationary state distribution (discounted state occupation).</p>
<blockquote>
<p><strong>Problem</strong>: the samples used to update the policy should be distributed according to the discounted state distribution $d^\pi_\gamma(s)$ however, the sample actually used in most algorithm are $s_{t+1}\sim p(s_{t+1}|s_t,a_t),a_t\sim \pi(s_t|a_t)$. In average return case, it is allowed because we can reach the limiting distribution by continuously running the simulation, i.e. $d^\pi(s)=\lim_{t\rightarrow \infty}p(s_{t}=s|s_0)$. But in the discounted case, we can&rsquo;t naively take average of samples from reply buffer as the discounted state stationary distribution treat observations sampled at different time steps differently.</p>
</blockquote>
<h1 id="reference">Reference</h1>
<ol>
<li>Wang, D., &amp; Hu, M. (2021). Deep Deterministic Policy Gradient With Compatible Critic Network. <em>IEEE Transactions on Neural Networks and Learning Systems</em>.</li>
<li>Diddigi, R. B., Jain, P., &amp; Bhatnagar, S. (2021). Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm. <em>arXiv preprint arXiv:2110.10017</em>.</li>
<li>Balduzzi, D., &amp; Ghifary, M. (2015). Compatible value gradients for reinforcement learning of continuous deep policies. <em>arXiv preprint arXiv:1509.03005</em>.</li>
<li>Russo Alessio. (2021) Why there is a problem with the Policy Gradient theorem in Deep Reinforcement Learning. <a href="https://towardsdatascience.com/why-there-is-a-problem-with-the-policy-gradient-theorem-in-deep-reinforcement-learning-958d845218f1" target="_blank" rel="noopener">https://towardsdatascience.com/why-there-is-a-problem-with-the-policy-gradient-theorem-in-deep-reinforcement-learning-958d845218f1</a></li>
<li>Chris Nota and Philip S. Thomas. 2020. Is the Policy Gradient a Gradient?. AAMAS (2020).</li>
<li>Naik, A., Shariff, R., Yasui, N., Yao, H., &amp; Sutton, R. S. (2019). Discounted reinforcement learning is not an optimization problem. NeurIPS 2019.</li>
</ol>

    </div>

    




<div class="article-tags">
  
  <a class="badge badge-light" href="/hua.zheng/tag/reinforcement-learning/">Reinforcement Learning</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/&amp;text=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/&amp;t=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory&amp;body=https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/&amp;title=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory%20https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://zhenghuazx.github.io/hua.zheng/post/somegapsrl/&amp;title=Some%20Gaps%20Between%20Reinforcement%20Learning%20Practice%20and%20Theory" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://zhenghuazx.github.io/hua.zheng"><img class="avatar mr-3 avatar-circle" src="/hua.zheng/authors/admin/avatar_hud022da434daf9b95cd9cbe8631130a77_14418_270x270_fill_q100_lanczos_center.jpg" alt="Hua Zheng"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://zhenghuazx.github.io/hua.zheng">Hua Zheng</a></h5>
      <h6 class="card-subtitle">PHD Candidate &amp; ML Scientist</h6>
      <p class="card-text">My research interests include reinforcement learning, machine learning and stochastic optimization.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/hua.zheng/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/HuaZhen96028186" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/zhenghuazx" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/hua-zheng-b064a8b0/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/hua.zheng/media/resume.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  







  
  
  

  

  
  <section id="comments">
    
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "zheng-h-personal" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </section>
  










  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2022 Hua Zheng. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

      

    
    <script src="/hua.zheng/js/vendor-bundle.min.fab8b449b814cc9f95b22fcf2e45f05b.js"></script>

    
    
    
      

      
      

      

      
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js" crossorigin="anonymous"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    
      <script id="dsq-count-scr" src="https://zheng-h-personal.disqus.com/count.js" async></script>
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/hua.zheng/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>
    
    
    
    
    
    
    
      
      
    
    
    <script src="/hua.zheng/en/js/wowchemy.min.ee0a656dd64ac48bd8f1b018d51bda8e.js"></script>

    
    
    
    
    
    
      
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      <script src="/hua.zheng/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>






</body>
</html>
